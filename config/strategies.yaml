# Configuration for MochiRAG models and strategies

# Embedding models configuration
embeddings:
  # Default model for embedding text. Excellent performance for its size.
  all-MiniLM-L6-v2:
    provider: ollama # Indicates it's a SentenceTransformer model
    model_name: "mahonzhan/all-MiniLM-L6-v2:latest"
    base_url: "http://localhost:11434"

# Large Language Models (LLM) configuration
llms:
  # Default LLM for chat and other tasks. Using a small, fast Gemma model.
  gemma3:4b-it-qat:
    provider: ollama  
    model_name: "gemma3:4b-it-qat" # Using a standard name, as gemma3:4b-it-qat might be custom
    base_url: "http://localhost:11434"

# Retriever strategies configuration
retrievers:
  # Configuration for the basic semantic search
  basic:
    strategy_class: "BasicRetrieverStrategy"
    description: "A standard vector similarity search."
    parameters:
      k: 5 # Number of documents to retrieve
  multiquery:
    strategy_class: "MultiQueryRetrieverStrategy"
    description: "Generates multiple queries from different perspectives for a given user question."
    parameters: {}
  compression:
    strategy_class: "ContextualCompressionRetrieverStrategy"
    description: "Compresses retrieved documents to extract only the relevant information."
    parameters: {}
  parent_document:
    strategy_class: "ParentDocumentRetrieverStrategy"
    description: "Retrieves smaller chunks of documents and returns the parent document."
    parameters:
      parent_chunk_size: 2000
      child_chunk_size: 400
  deeprag:
    strategy_class: "DeepRAGStrategy"
    description: "Decomposes complex questions into a series of simpler subqueries to build a comprehensive answer."
    parameters: {}