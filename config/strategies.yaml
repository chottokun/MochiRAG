# Configuration for MochiRAG models and strategies

# Vector Store Configuration
# Configure the vector store used by the application.
# `provider`: Currently only 'chromadb' is supported.
# `mode`: 'persistent' for local file-based storage, 'http' for client-server mode.
# `host`: The hostname of the ChromaDB server (only for 'http' mode).
# `port`: The port of the ChromaDB server (only for 'http' mode).
# `path`: The local directory to store database files (only for 'persistent' mode).
vector_store:
  provider: chromadb
  mode: http # 'persistent # Can be 'persistent' or 'http'
  host: localhost
  port: 8001  # Changed to 8001 to avoid conflict with backend uvicorn (8000)
  path: "chroma_db"

# Embedding models configuration
embeddings:
  # Default model for embedding text. Excellent performance for its size.
  all-MiniLM-L6-v2:
    provider: ollama # Indicates it's a SentenceTransformer model
    model_name: "mahonzhan/all-MiniLM-L6-v2:latest"
    base_url: "http://localhost:11434"

  ruri-v3-30m:
    provider: openai_compatible
    model_name: "cl-nagoya/ruri-v3-30m"
    base_url: "http://embedding_api:8000/v1"

# Large Language Models (LLM) configuration
llms:
  # Role mappings: Define which provider configuration to use for a given role.
  roles:
    main: gemma3:4b-it-qat
    fast: gemma3:4b-it-qat
    # vision: gemini-1.5-pro # Example for future extension

  # Provider configurations: Define the settings for each individual model.
  providers:
    gemma3:4b-it-qat:
      provider: ollama  
      model_name: "gemma3:4b-it-qat"
      base_url: "http://localhost:11434"

    gpt-4o:
      provider: openai
      model_name: "gpt-4o"
      api_key: "${OPENAI_API_KEY}" # Loaded from .env file
      temperature: 0.7

    azure-gpt-4:
      provider: azure
      deployment_name: "YOUR_DEPLOYMENT_NAME"
      azure_endpoint: "YOUR_AZURE_ENDPOINT"
      api_version: "2024-02-01"
      api_key: "${AZURE_OPENAI_API_KEY}" # Loaded from .env file
      temperature: 0.7

    gemini-1.5-pro:
      provider: gemini
      model_name: "gemini-1.5-pro-latest"
      api_key: "${GOOGLE_API_KEY}" # Loaded from .env file
      temperature: 0.7

# Retriever strategies configuration
retrievers:
  # Configuration for the basic semantic search
  basic:
    strategy_class: "BasicRetrieverStrategy"
    description: "A standard vector similarity search."
    parameters:
      k: 5 # Number of documents to retrieve
      # Text splitting (chunking) controls used when ingesting documents for this retriever.
      # You can tune these to balance retrieval granularity vs. context size.
      # - chunk_size: approx. characters per chunk (default shown here)
      # - chunk_overlap: characters overlap between adjacent chunks
      # Example (defaults):
      chunk_size: 1000
      chunk_overlap: 200
  multiquery:
    strategy_class: "MultiQueryRetrieverStrategy"
    description: "Generates multiple queries from different perspectives for a given user question."
    parameters: {}
  compression:
    strategy_class: "ContextualCompressionRetrieverStrategy"
    description: "Compresses retrieved documents to extract only the relevant information."
    parameters: {}
  parent_document:
    strategy_class: "ParentDocumentRetrieverStrategy"
    description: "Retrieves smaller chunks of documents and returns the parent document."
    parameters:
      # Parent/child chunking controls. Parent chunks are larger documents
      # that will be returned to the LLM, while child chunks are the
      # smaller indexed chunks used for retrieval.
      parent_chunk_size: 2000
      parent_chunk_overlap: 200
      child_chunk_size: 400
      child_chunk_overlap: 100
  step_back:
    strategy_class: "StepBackPromptingRetrieverStrategy"
    description: "Generates a more general 'step-back' question to improve retrieval for broad queries."
    parameters: {}
  deeprag:
    strategy_class: "DeepRAGStrategy"
    description: "Decomposes complex questions into a series of simpler subqueries to build a comprehensive answer."
    parameters: {}
  ace:
    strategy_class: "ACERetrieverStrategy"
    description: "A self-evolving strategy that learns from interactions to improve context retrieval over time."
    parameters: {}